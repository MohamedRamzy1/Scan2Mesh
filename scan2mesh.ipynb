{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0750b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from data.shapenet import ShapeNet\n",
    "from model.vertix_model import VertixModel\n",
    "import tqdm\n",
    "from util.visualization import visualize_pointcloud\n",
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe67a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment_name': 'vertix_training',\n",
    "    'device': 'cuda:0',  \n",
    "    'is_overfit': False,\n",
    "    'batch_size': 8,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 100,\n",
    "    'print_every_n': 10,\n",
    "    'validate_every_n': 1000,\n",
    "    'sdf_path': 'data/shapenet_dim32_sdf',\n",
    "    'meshes_path': 'data/shapenet_reduced',\n",
    "    'class_mapping': 'data/shape_info.json',\n",
    "    'split': 'train',\n",
    "    'num_vertices': num_vertices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e5e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vertices=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33d4f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ShapeNet(sdf_path=config[\"sdf_path\"],\n",
    "                         meshes_path=config[\"meshes_path\"],\n",
    "                         class_mapping=config[\"class_mapping\"],\n",
    "                         split = \"val\", threshold=config[\"num_vertices\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "470e1387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 32304\n",
      "Filtering data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32304/32304 [00:25<00:00, 1285.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 26232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataset.filter_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a969311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Length of dataset: 153528\n",
      "Filtering data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153528/153528 [01:28<00:00, 1728.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 123840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123840/123840 [00:00<00:00, 1096108.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 03001627 has 25944 shapes\n",
      "Class 04256520 has 15198 shapes\n",
      "Class 04379243 has 28782 shapes\n",
      "Class 02691156 has 19590 shapes\n",
      "Class 04530566 has 8628 shapes\n",
      "Class 02958343 has 11106 shapes\n",
      "Class 03636649 has 7890 shapes\n",
      "Class 02933112 has 6702 shapes\n",
      "Length of dataset: 32304\n",
      "Filtering data ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32304/32304 [00:18<00:00, 1701.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 26232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26232/26232 [00:00<00:00, 1115758.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 02691156 has 4404 shapes\n",
      "Class 04530566 has 1782 shapes\n",
      "Class 04379243 has 5778 shapes\n",
      "Class 03001627 has 5286 shapes\n",
      "Class 04256520 has 3330 shapes\n",
      "Class 03636649 has 1998 shapes\n",
      "Class 02958343 has 2262 shapes\n",
      "Class 02933112 has 1392 shapes\n",
      "[000/00009] train_loss: 0.180010\n",
      "[000/00019] train_loss: 0.144125\n",
      "[000/00029] train_loss: 0.105706\n",
      "[000/00039] train_loss: 0.078603\n",
      "[000/00049] train_loss: 0.067446\n",
      "[000/00059] train_loss: 0.063306\n",
      "[000/00069] train_loss: 0.059904\n",
      "[000/00079] train_loss: 0.064579\n",
      "[000/00089] train_loss: 0.066666\n",
      "[000/00099] train_loss: 0.065760\n",
      "[000/00109] train_loss: 0.074814\n",
      "[000/00119] train_loss: 0.053911\n",
      "[000/00129] train_loss: 0.056307\n",
      "[000/00139] train_loss: 0.049515\n",
      "[000/00149] train_loss: 0.061867\n",
      "[000/00159] train_loss: 0.060769\n",
      "[000/00169] train_loss: 0.052047\n",
      "[000/00179] train_loss: 0.050019\n",
      "[000/00189] train_loss: 0.057023\n",
      "[000/00199] train_loss: 0.056117\n",
      "[000/00209] train_loss: 0.058514\n",
      "[000/00219] train_loss: 0.058104\n",
      "[000/00229] train_loss: 0.060191\n",
      "[000/00239] train_loss: 0.063112\n",
      "[000/00249] train_loss: 0.061315\n",
      "[000/00259] train_loss: 0.063217\n",
      "[000/00269] train_loss: 0.061857\n",
      "[000/00279] train_loss: 0.055967\n",
      "[000/00289] train_loss: 0.053029\n",
      "[000/00299] train_loss: 0.048001\n",
      "[000/00309] train_loss: 0.058955\n",
      "[000/00319] train_loss: 0.054628\n",
      "[000/00329] train_loss: 0.052177\n",
      "[000/00339] train_loss: 0.064238\n",
      "[000/00349] train_loss: 0.048523\n",
      "[000/00359] train_loss: 0.050288\n",
      "[000/00369] train_loss: 0.051145\n",
      "[000/00379] train_loss: 0.052355\n",
      "[000/00389] train_loss: 0.047733\n",
      "[000/00399] train_loss: 0.050459\n",
      "[000/00409] train_loss: 0.051947\n",
      "[000/00419] train_loss: 0.051573\n",
      "[000/00429] train_loss: 0.056167\n",
      "[000/00439] train_loss: 0.051063\n",
      "[000/00449] train_loss: 0.053344\n",
      "[000/00459] train_loss: 0.046227\n",
      "[000/00469] train_loss: 0.056367\n",
      "[000/00479] train_loss: 0.057290\n",
      "[000/00489] train_loss: 0.055938\n",
      "[000/00499] train_loss: 0.052248\n",
      "[000/00509] train_loss: 0.048464\n",
      "[000/00519] train_loss: 0.059328\n",
      "[000/00529] train_loss: 0.056318\n",
      "[000/00539] train_loss: 0.050521\n",
      "[000/00549] train_loss: 0.050038\n",
      "[000/00559] train_loss: 0.055654\n",
      "[000/00569] train_loss: 0.049068\n",
      "[000/00579] train_loss: 0.049221\n",
      "[000/00589] train_loss: 0.058843\n",
      "[000/00599] train_loss: 0.052813\n",
      "[000/00609] train_loss: 0.046509\n",
      "[000/00619] train_loss: 0.047166\n",
      "[000/00629] train_loss: 0.058526\n",
      "[000/00639] train_loss: 0.044841\n",
      "[000/00649] train_loss: 0.049758\n",
      "[000/00659] train_loss: 0.051666\n",
      "[000/00669] train_loss: 0.050095\n",
      "[000/00679] train_loss: 0.052254\n",
      "[000/00689] train_loss: 0.041970\n",
      "[000/00699] train_loss: 0.048587\n",
      "[000/00709] train_loss: 0.052706\n",
      "[000/00719] train_loss: 0.042087\n",
      "[000/00729] train_loss: 0.041533\n",
      "[000/00739] train_loss: 0.042110\n",
      "[000/00749] train_loss: 0.040346\n",
      "[000/00759] train_loss: 0.044053\n",
      "[000/00769] train_loss: 0.043522\n",
      "[000/00779] train_loss: 0.042408\n",
      "[000/00789] train_loss: 0.042980\n",
      "[000/00799] train_loss: 0.043230\n",
      "[000/00809] train_loss: 0.044133\n",
      "[000/00819] train_loss: 0.041988\n",
      "[000/00829] train_loss: 0.043318\n",
      "[000/00839] train_loss: 0.047459\n",
      "[000/00849] train_loss: 0.043020\n",
      "[000/00859] train_loss: 0.047472\n",
      "[000/00869] train_loss: 0.040016\n",
      "[000/00879] train_loss: 0.046700\n",
      "[000/00889] train_loss: 0.039195\n",
      "[000/00899] train_loss: 0.041829\n",
      "[000/00909] train_loss: 0.048424\n",
      "[000/00919] train_loss: 0.036366\n",
      "[000/00929] train_loss: 0.043075\n",
      "[000/00939] train_loss: 0.038669\n",
      "[000/00949] train_loss: 0.040100\n",
      "[000/00959] train_loss: 0.045342\n",
      "[000/00969] train_loss: 0.041292\n",
      "[000/00979] train_loss: 0.040351\n",
      "[000/00989] train_loss: 0.038626\n",
      "[000/00999] train_loss: 0.036146\n",
      "[000/00999] val_loss: 0.036275 | best_loss_val: 0.036275\n",
      "[000/01009] train_loss: 0.042173\n",
      "[000/01019] train_loss: 0.039781\n",
      "[000/01029] train_loss: 0.040245\n",
      "[000/01039] train_loss: 0.041123\n",
      "[000/01049] train_loss: 0.037419\n",
      "[000/01059] train_loss: 0.036756\n",
      "[000/01069] train_loss: 0.034743\n",
      "[000/01079] train_loss: 0.037284\n",
      "[000/01089] train_loss: 0.033676\n",
      "[000/01099] train_loss: 0.038797\n",
      "[000/01109] train_loss: 0.033941\n",
      "[000/01119] train_loss: 0.039617\n",
      "[000/01129] train_loss: 0.040724\n",
      "[000/01139] train_loss: 0.035067\n",
      "[000/01149] train_loss: 0.037308\n",
      "[000/01159] train_loss: 0.034978\n",
      "[000/01169] train_loss: 0.038481\n",
      "[000/01179] train_loss: 0.039155\n",
      "[000/01189] train_loss: 0.039272\n",
      "[000/01199] train_loss: 0.035978\n",
      "[000/01209] train_loss: 0.036795\n",
      "[000/01219] train_loss: 0.041413\n",
      "[000/01229] train_loss: 0.042122\n",
      "[000/01239] train_loss: 0.044086\n",
      "[000/01249] train_loss: 0.036278\n",
      "[000/01259] train_loss: 0.036630\n",
      "[000/01269] train_loss: 0.033628\n",
      "[000/01279] train_loss: 0.041090\n",
      "[000/01289] train_loss: 0.039704\n",
      "[000/01299] train_loss: 0.039510\n",
      "[000/01309] train_loss: 0.038503\n",
      "[000/01319] train_loss: 0.035073\n",
      "[000/01329] train_loss: 0.033471\n",
      "[000/01339] train_loss: 0.031852\n",
      "[000/01349] train_loss: 0.031526\n",
      "[000/01359] train_loss: 0.035002\n",
      "[000/01369] train_loss: 0.035562\n",
      "[000/01379] train_loss: 0.041218\n",
      "[000/01389] train_loss: 0.033278\n",
      "[000/01399] train_loss: 0.035826\n",
      "[000/01409] train_loss: 0.038379\n",
      "[000/01419] train_loss: 0.035053\n",
      "[000/01429] train_loss: 0.041800\n",
      "[000/01439] train_loss: 0.040558\n",
      "[000/01449] train_loss: 0.034047\n",
      "[000/01459] train_loss: 0.036405\n",
      "[000/01469] train_loss: 0.033325\n",
      "[000/01479] train_loss: 0.035160\n",
      "[000/01489] train_loss: 0.031557\n",
      "[000/01499] train_loss: 0.028922\n",
      "[000/01509] train_loss: 0.038389\n",
      "[000/01519] train_loss: 0.037679\n",
      "[000/01529] train_loss: 0.034378\n",
      "[000/01539] train_loss: 0.035341\n",
      "[000/01549] train_loss: 0.042756\n",
      "[000/01559] train_loss: 0.036362\n",
      "[000/01569] train_loss: 0.031095\n",
      "[000/01579] train_loss: 0.030954\n",
      "[000/01589] train_loss: 0.031960\n",
      "[000/01599] train_loss: 0.029735\n",
      "[000/01609] train_loss: 0.036280\n",
      "[000/01619] train_loss: 0.040337\n",
      "[000/01629] train_loss: 0.033644\n",
      "[000/01639] train_loss: 0.031863\n",
      "[000/01649] train_loss: 0.030611\n",
      "[000/01659] train_loss: 0.034130\n",
      "[000/01669] train_loss: 0.030999\n",
      "[000/01679] train_loss: 0.030718\n",
      "[000/01689] train_loss: 0.034904\n",
      "[000/01699] train_loss: 0.039647\n",
      "[000/01709] train_loss: 0.030288\n",
      "[000/01719] train_loss: 0.033267\n",
      "[000/01729] train_loss: 0.035830\n",
      "[000/01739] train_loss: 0.029987\n",
      "[000/01749] train_loss: 0.032461\n",
      "[000/01759] train_loss: 0.030388\n",
      "[000/01769] train_loss: 0.037885\n",
      "[000/01779] train_loss: 0.030630\n",
      "[000/01789] train_loss: 0.031600\n",
      "[000/01799] train_loss: 0.029411\n",
      "[000/01809] train_loss: 0.035694\n",
      "[000/01819] train_loss: 0.031942\n",
      "[000/01829] train_loss: 0.031347\n",
      "[000/01839] train_loss: 0.028323\n",
      "[000/01849] train_loss: 0.035542\n",
      "[000/01859] train_loss: 0.029096\n",
      "[000/01869] train_loss: 0.031449\n",
      "[000/01879] train_loss: 0.037520\n",
      "[000/01889] train_loss: 0.031234\n",
      "[000/01899] train_loss: 0.029845\n",
      "[000/01909] train_loss: 0.029835\n",
      "[000/01919] train_loss: 0.033510\n",
      "[000/01929] train_loss: 0.034009\n",
      "[000/01939] train_loss: 0.029578\n",
      "[000/01949] train_loss: 0.028306\n",
      "[000/01959] train_loss: 0.028756\n",
      "[000/01969] train_loss: 0.036650\n",
      "[000/01979] train_loss: 0.033441\n",
      "[000/01989] train_loss: 0.031505\n",
      "[000/01999] train_loss: 0.034488\n",
      "[000/01999] val_loss: 0.027737 | best_loss_val: 0.027737\n",
      "[000/02009] train_loss: 0.031726\n",
      "[000/02019] train_loss: 0.031335\n",
      "[000/02029] train_loss: 0.031608\n",
      "[000/02039] train_loss: 0.032360\n",
      "[000/02049] train_loss: 0.031670\n",
      "[000/02059] train_loss: 0.030667\n",
      "[000/02069] train_loss: 0.028854\n",
      "[000/02079] train_loss: 0.030545\n",
      "[000/02089] train_loss: 0.032222\n",
      "[000/02099] train_loss: 0.030418\n",
      "[000/02109] train_loss: 0.035912\n",
      "[000/02119] train_loss: 0.034563\n",
      "[000/02129] train_loss: 0.036244\n",
      "[000/02139] train_loss: 0.029777\n",
      "[000/02149] train_loss: 0.030978\n",
      "[000/02159] train_loss: 0.030353\n",
      "[000/02169] train_loss: 0.026531\n",
      "[000/02179] train_loss: 0.033031\n",
      "[000/02189] train_loss: 0.032036\n",
      "[000/02199] train_loss: 0.031010\n",
      "[000/02209] train_loss: 0.031906\n",
      "[000/02219] train_loss: 0.028951\n",
      "[000/02229] train_loss: 0.027056\n",
      "[000/02239] train_loss: 0.026717\n",
      "[000/02249] train_loss: 0.028344\n",
      "[000/02259] train_loss: 0.028999\n",
      "[000/02269] train_loss: 0.028022\n",
      "[000/02279] train_loss: 0.024069\n",
      "[000/02289] train_loss: 0.030783\n",
      "[000/02299] train_loss: 0.032478\n",
      "[000/02309] train_loss: 0.028120\n",
      "[000/02319] train_loss: 0.025971\n",
      "[000/02329] train_loss: 0.034196\n",
      "[000/02339] train_loss: 0.028246\n",
      "[000/02349] train_loss: 0.027206\n",
      "[000/02359] train_loss: 0.029533\n",
      "[000/02369] train_loss: 0.034349\n",
      "[000/02379] train_loss: 0.036058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000/02389] train_loss: 0.030110\n",
      "[000/02399] train_loss: 0.027732\n",
      "[000/02409] train_loss: 0.032219\n",
      "[000/02419] train_loss: 0.027418\n",
      "[000/02429] train_loss: 0.030884\n",
      "[000/02439] train_loss: 0.026708\n",
      "[000/02449] train_loss: 0.030973\n",
      "[000/02459] train_loss: 0.028164\n",
      "[000/02469] train_loss: 0.028264\n",
      "[000/02479] train_loss: 0.026790\n",
      "[000/02489] train_loss: 0.028294\n",
      "[000/02499] train_loss: 0.031190\n",
      "[000/02509] train_loss: 0.025251\n",
      "[000/02519] train_loss: 0.025466\n",
      "[000/02529] train_loss: 0.026015\n",
      "[000/02539] train_loss: 0.031314\n",
      "[000/02549] train_loss: 0.030252\n",
      "[000/02559] train_loss: 0.027764\n",
      "[000/02569] train_loss: 0.028264\n",
      "[000/02579] train_loss: 0.024524\n",
      "[000/02589] train_loss: 0.024746\n",
      "[000/02599] train_loss: 0.025925\n",
      "[000/02609] train_loss: 0.029040\n",
      "[000/02619] train_loss: 0.028824\n",
      "[000/02629] train_loss: 0.028852\n",
      "[000/02639] train_loss: 0.032240\n",
      "[000/02649] train_loss: 0.028266\n",
      "[000/02659] train_loss: 0.029533\n",
      "[000/02669] train_loss: 0.032661\n",
      "[000/02679] train_loss: 0.027992\n",
      "[000/02689] train_loss: 0.028964\n",
      "[000/02699] train_loss: 0.030196\n",
      "[000/02709] train_loss: 0.030059\n",
      "[000/02719] train_loss: 0.027859\n",
      "[000/02729] train_loss: 0.028052\n",
      "[000/02739] train_loss: 0.030411\n",
      "[000/02749] train_loss: 0.028355\n",
      "[000/02759] train_loss: 0.025382\n",
      "[000/02769] train_loss: 0.026154\n",
      "[000/02779] train_loss: 0.026224\n",
      "[000/02789] train_loss: 0.030429\n",
      "[000/02799] train_loss: 0.027086\n",
      "[000/02809] train_loss: 0.029615\n",
      "[000/02819] train_loss: 0.027122\n",
      "[000/02829] train_loss: 0.025086\n",
      "[000/02839] train_loss: 0.028849\n",
      "[000/02849] train_loss: 0.032634\n",
      "[000/02859] train_loss: 0.023887\n",
      "[000/02869] train_loss: 0.026991\n",
      "[000/02879] train_loss: 0.029907\n",
      "[000/02889] train_loss: 0.034409\n",
      "[000/02899] train_loss: 0.030261\n",
      "[000/02909] train_loss: 0.027130\n",
      "[000/02919] train_loss: 0.026187\n",
      "[000/02929] train_loss: 0.028472\n",
      "[000/02939] train_loss: 0.028021\n",
      "[000/02949] train_loss: 0.024841\n",
      "[000/02959] train_loss: 0.026659\n",
      "[000/02969] train_loss: 0.028763\n",
      "[000/02979] train_loss: 0.027806\n",
      "[000/02989] train_loss: 0.026369\n",
      "[000/02999] train_loss: 0.024183\n",
      "[000/02999] val_loss: 0.023430 | best_loss_val: 0.023430\n",
      "[000/03009] train_loss: 0.029236\n",
      "[000/03019] train_loss: 0.024030\n",
      "[000/03029] train_loss: 0.027800\n",
      "[000/03039] train_loss: 0.026773\n",
      "[000/03049] train_loss: 0.027297\n",
      "[000/03059] train_loss: 0.026788\n",
      "[000/03069] train_loss: 0.024519\n",
      "[000/03079] train_loss: 0.030823\n",
      "[000/03089] train_loss: 0.030543\n",
      "[000/03099] train_loss: 0.029078\n",
      "[000/03109] train_loss: 0.027776\n",
      "[000/03119] train_loss: 0.031418\n",
      "[000/03129] train_loss: 0.030369\n",
      "[000/03139] train_loss: 0.028498\n",
      "[000/03149] train_loss: 0.028304\n",
      "[000/03159] train_loss: 0.034685\n",
      "[000/03169] train_loss: 0.025553\n",
      "[000/03179] train_loss: 0.029665\n",
      "[000/03189] train_loss: 0.025194\n",
      "[000/03199] train_loss: 0.023599\n",
      "[000/03209] train_loss: 0.021532\n",
      "[000/03219] train_loss: 0.023423\n",
      "[000/03229] train_loss: 0.026094\n",
      "[000/03239] train_loss: 0.022757\n",
      "[000/03249] train_loss: 0.021373\n",
      "[000/03259] train_loss: 0.029869\n",
      "[000/03269] train_loss: 0.022753\n",
      "[000/03279] train_loss: 0.027984\n",
      "[000/03289] train_loss: 0.027636\n",
      "[000/03299] train_loss: 0.025114\n",
      "[000/03309] train_loss: 0.024804\n",
      "[000/03319] train_loss: 0.032672\n",
      "[000/03329] train_loss: 0.025595\n",
      "[000/03339] train_loss: 0.025154\n",
      "[000/03349] train_loss: 0.024685\n",
      "[000/03359] train_loss: 0.021556\n",
      "[000/03369] train_loss: 0.027286\n",
      "[000/03379] train_loss: 0.023777\n",
      "[000/03389] train_loss: 0.025118\n",
      "[000/03399] train_loss: 0.024334\n",
      "[000/03409] train_loss: 0.026937\n",
      "[000/03419] train_loss: 0.031283\n",
      "[000/03429] train_loss: 0.024024\n",
      "[000/03439] train_loss: 0.022144\n",
      "[000/03449] train_loss: 0.024590\n",
      "[000/03459] train_loss: 0.021889\n",
      "[000/03469] train_loss: 0.026899\n",
      "[000/03479] train_loss: 0.023167\n",
      "[000/03489] train_loss: 0.030948\n",
      "[000/03499] train_loss: 0.023458\n",
      "[000/03509] train_loss: 0.025081\n",
      "[000/03519] train_loss: 0.022784\n",
      "[000/03529] train_loss: 0.023031\n",
      "[000/03539] train_loss: 0.023359\n",
      "[000/03549] train_loss: 0.026841\n",
      "[000/03559] train_loss: 0.024242\n",
      "[000/03569] train_loss: 0.023131\n",
      "[000/03579] train_loss: 0.024144\n",
      "[000/03589] train_loss: 0.020209\n",
      "[000/03599] train_loss: 0.023373\n",
      "[000/03609] train_loss: 0.026625\n",
      "[000/03619] train_loss: 0.026479\n",
      "[000/03629] train_loss: 0.023119\n",
      "[000/03639] train_loss: 0.022498\n",
      "[000/03649] train_loss: 0.025024\n",
      "[000/03659] train_loss: 0.028529\n",
      "[000/03669] train_loss: 0.025841\n",
      "[000/03679] train_loss: 0.023981\n",
      "[000/03689] train_loss: 0.027815\n",
      "[000/03699] train_loss: 0.024853\n",
      "[000/03709] train_loss: 0.025726\n",
      "[000/03719] train_loss: 0.028343\n",
      "[000/03729] train_loss: 0.025723\n",
      "[000/03739] train_loss: 0.025802\n",
      "[000/03749] train_loss: 0.027508\n",
      "[000/03759] train_loss: 0.026045\n",
      "[000/03769] train_loss: 0.021931\n",
      "[000/03779] train_loss: 0.023858\n",
      "[000/03789] train_loss: 0.025406\n",
      "[000/03799] train_loss: 0.025038\n",
      "[000/03809] train_loss: 0.022616\n",
      "[000/03819] train_loss: 0.022752\n",
      "[000/03829] train_loss: 0.025963\n",
      "[000/03839] train_loss: 0.024080\n",
      "[000/03849] train_loss: 0.023463\n",
      "[000/03859] train_loss: 0.025646\n",
      "[000/03869] train_loss: 0.018721\n",
      "[000/03879] train_loss: 0.022718\n",
      "[000/03889] train_loss: 0.024534\n",
      "[000/03899] train_loss: 0.024045\n",
      "[000/03909] train_loss: 0.026457\n",
      "[000/03919] train_loss: 0.024587\n",
      "[000/03929] train_loss: 0.022716\n",
      "[000/03939] train_loss: 0.029444\n",
      "[000/03949] train_loss: 0.024378\n",
      "[000/03959] train_loss: 0.022544\n",
      "[000/03969] train_loss: 0.024277\n",
      "[000/03979] train_loss: 0.028050\n",
      "[000/03989] train_loss: 0.027158\n",
      "[000/03999] train_loss: 0.024188\n",
      "[000/03999] val_loss: 0.021618 | best_loss_val: 0.021618\n",
      "[000/04009] train_loss: 0.024454\n",
      "[000/04019] train_loss: 0.025174\n",
      "[000/04029] train_loss: 0.029423\n",
      "[000/04039] train_loss: 0.023979\n",
      "[000/04049] train_loss: 0.023550\n",
      "[000/04059] train_loss: 0.023308\n",
      "[000/04069] train_loss: 0.025909\n",
      "[000/04079] train_loss: 0.023950\n",
      "[000/04089] train_loss: 0.027272\n",
      "[000/04099] train_loss: 0.022237\n",
      "[000/04109] train_loss: 0.025989\n",
      "[000/04119] train_loss: 0.030463\n",
      "[000/04129] train_loss: 0.024398\n",
      "[000/04139] train_loss: 0.025356\n",
      "[000/04149] train_loss: 0.024702\n",
      "[000/04159] train_loss: 0.026733\n",
      "[000/04169] train_loss: 0.027415\n",
      "[000/04179] train_loss: 0.025455\n",
      "[000/04189] train_loss: 0.020245\n",
      "[000/04199] train_loss: 0.021726\n",
      "[000/04209] train_loss: 0.023428\n",
      "[000/04219] train_loss: 0.021057\n",
      "[000/04229] train_loss: 0.022074\n",
      "[000/04239] train_loss: 0.025216\n",
      "[000/04249] train_loss: 0.030361\n",
      "[000/04259] train_loss: 0.022297\n",
      "[000/04269] train_loss: 0.024336\n",
      "[000/04279] train_loss: 0.029668\n",
      "[000/04289] train_loss: 0.021163\n",
      "[000/04299] train_loss: 0.028659\n",
      "[000/04309] train_loss: 0.022594\n",
      "[000/04319] train_loss: 0.022543\n",
      "[000/04329] train_loss: 0.022079\n",
      "[000/04339] train_loss: 0.026714\n",
      "[000/04349] train_loss: 0.021746\n",
      "[000/04359] train_loss: 0.024636\n",
      "[000/04369] train_loss: 0.022449\n",
      "[000/04379] train_loss: 0.029270\n",
      "[000/04389] train_loss: 0.028536\n",
      "[000/04399] train_loss: 0.024582\n",
      "[000/04409] train_loss: 0.028729\n",
      "[000/04419] train_loss: 0.020685\n",
      "[000/04429] train_loss: 0.024567\n",
      "[000/04439] train_loss: 0.023703\n",
      "[000/04449] train_loss: 0.022284\n",
      "[000/04459] train_loss: 0.025125\n",
      "[000/04469] train_loss: 0.021959\n",
      "[000/04479] train_loss: 0.026287\n",
      "[000/04489] train_loss: 0.021780\n",
      "[000/04499] train_loss: 0.024751\n",
      "[000/04509] train_loss: 0.020823\n",
      "[000/04519] train_loss: 0.021518\n",
      "[000/04529] train_loss: 0.022388\n",
      "[000/04539] train_loss: 0.022525\n",
      "[000/04549] train_loss: 0.022983\n",
      "[000/04559] train_loss: 0.021777\n",
      "[000/04569] train_loss: 0.025548\n",
      "[000/04579] train_loss: 0.024774\n",
      "[000/04589] train_loss: 0.021883\n",
      "[000/04599] train_loss: 0.022742\n",
      "[000/04609] train_loss: 0.025644\n",
      "[000/04619] train_loss: 0.026406\n",
      "[000/04629] train_loss: 0.022002\n",
      "[000/04639] train_loss: 0.024649\n",
      "[000/04649] train_loss: 0.023751\n",
      "[000/04659] train_loss: 0.022312\n",
      "[000/04669] train_loss: 0.020105\n",
      "[000/04679] train_loss: 0.023220\n",
      "[000/04689] train_loss: 0.027540\n",
      "[000/04699] train_loss: 0.020513\n",
      "[000/04709] train_loss: 0.021298\n",
      "[000/04719] train_loss: 0.021571\n",
      "[000/04729] train_loss: 0.023708\n",
      "[000/04739] train_loss: 0.023897\n",
      "[000/04749] train_loss: 0.023676\n",
      "[000/04759] train_loss: 0.024124\n",
      "[000/04769] train_loss: 0.026709\n",
      "[000/04779] train_loss: 0.022562\n",
      "[000/04789] train_loss: 0.024124\n",
      "[000/04799] train_loss: 0.025217\n",
      "[000/04809] train_loss: 0.022970\n",
      "[000/04819] train_loss: 0.028751\n",
      "[000/04829] train_loss: 0.025656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000/04839] train_loss: 0.025245\n",
      "[000/04849] train_loss: 0.022980\n",
      "[000/04859] train_loss: 0.023411\n",
      "[000/04869] train_loss: 0.024967\n",
      "[000/04879] train_loss: 0.027066\n",
      "[000/04889] train_loss: 0.021315\n",
      "[000/04899] train_loss: 0.024405\n",
      "[000/04909] train_loss: 0.025841\n",
      "[000/04919] train_loss: 0.022750\n",
      "[000/04929] train_loss: 0.026444\n",
      "[000/04939] train_loss: 0.020725\n",
      "[000/04949] train_loss: 0.020877\n",
      "[000/04959] train_loss: 0.021841\n",
      "[000/04969] train_loss: 0.024197\n",
      "[000/04979] train_loss: 0.022094\n",
      "[000/04989] train_loss: 0.022394\n",
      "[000/04999] train_loss: 0.018258\n",
      "[000/04999] val_loss: 0.020092 | best_loss_val: 0.020092\n",
      "[000/05009] train_loss: 0.021702\n",
      "[000/05019] train_loss: 0.023782\n",
      "[000/05029] train_loss: 0.022704\n",
      "[000/05039] train_loss: 0.026917\n",
      "[000/05049] train_loss: 0.023809\n",
      "[000/05059] train_loss: 0.022615\n",
      "[000/05069] train_loss: 0.024737\n",
      "[000/05079] train_loss: 0.025113\n",
      "[000/05089] train_loss: 0.029903\n",
      "[000/05099] train_loss: 0.022877\n",
      "[000/05109] train_loss: 0.019560\n",
      "[000/05119] train_loss: 0.027727\n",
      "[000/05129] train_loss: 0.021451\n",
      "[000/05139] train_loss: 0.022797\n",
      "[000/05149] train_loss: 0.023782\n",
      "[000/05159] train_loss: 0.022611\n",
      "[000/05169] train_loss: 0.025649\n",
      "[000/05179] train_loss: 0.026031\n",
      "[000/05189] train_loss: 0.024638\n",
      "[000/05199] train_loss: 0.023273\n",
      "[000/05209] train_loss: 0.021111\n",
      "[000/05219] train_loss: 0.019687\n",
      "[000/05229] train_loss: 0.021823\n",
      "[000/05239] train_loss: 0.021273\n",
      "[000/05249] train_loss: 0.019732\n",
      "[000/05259] train_loss: 0.020080\n",
      "[000/05269] train_loss: 0.024173\n",
      "[000/05279] train_loss: 0.023628\n",
      "[000/05289] train_loss: 0.024019\n",
      "[000/05299] train_loss: 0.020931\n",
      "[000/05309] train_loss: 0.022546\n",
      "[000/05319] train_loss: 0.021198\n",
      "[000/05329] train_loss: 0.023985\n",
      "[000/05339] train_loss: 0.024588\n",
      "[000/05349] train_loss: 0.022983\n",
      "[000/05359] train_loss: 0.029608\n",
      "[000/05369] train_loss: 0.020961\n",
      "[000/05379] train_loss: 0.020415\n",
      "[000/05389] train_loss: 0.019108\n",
      "[000/05399] train_loss: 0.022689\n",
      "[000/05409] train_loss: 0.021488\n",
      "[000/05419] train_loss: 0.024069\n",
      "[000/05429] train_loss: 0.022921\n",
      "[000/05439] train_loss: 0.020981\n",
      "[000/05449] train_loss: 0.020707\n",
      "[000/05459] train_loss: 0.018339\n",
      "[000/05469] train_loss: 0.019730\n",
      "[000/05479] train_loss: 0.020946\n",
      "[000/05489] train_loss: 0.021047\n",
      "[000/05499] train_loss: 0.019696\n",
      "[000/05509] train_loss: 0.026089\n",
      "[000/05519] train_loss: 0.021600\n",
      "[000/05529] train_loss: 0.023589\n",
      "[000/05539] train_loss: 0.020550\n",
      "[000/05549] train_loss: 0.020342\n",
      "[000/05559] train_loss: 0.024373\n",
      "[000/05569] train_loss: 0.023845\n",
      "[000/05579] train_loss: 0.024213\n",
      "[000/05589] train_loss: 0.023755\n",
      "[000/05599] train_loss: 0.020779\n",
      "[000/05609] train_loss: 0.022053\n",
      "[000/05619] train_loss: 0.025179\n",
      "[000/05629] train_loss: 0.022347\n",
      "[000/05639] train_loss: 0.024872\n",
      "[000/05649] train_loss: 0.027580\n",
      "[000/05659] train_loss: 0.021892\n",
      "[000/05669] train_loss: 0.023464\n",
      "[000/05679] train_loss: 0.026854\n",
      "[000/05689] train_loss: 0.023318\n",
      "[000/05699] train_loss: 0.024413\n",
      "[000/05709] train_loss: 0.021335\n",
      "[000/05719] train_loss: 0.022022\n",
      "[000/05729] train_loss: 0.024707\n",
      "[000/05739] train_loss: 0.023223\n",
      "[000/05749] train_loss: 0.025416\n",
      "[000/05759] train_loss: 0.022341\n",
      "[000/05769] train_loss: 0.025797\n",
      "[000/05779] train_loss: 0.025235\n",
      "[000/05789] train_loss: 0.021445\n",
      "[000/05799] train_loss: 0.021941\n",
      "[000/05809] train_loss: 0.020754\n",
      "[000/05819] train_loss: 0.025165\n",
      "[000/05829] train_loss: 0.021869\n",
      "[000/05839] train_loss: 0.022312\n",
      "[000/05849] train_loss: 0.020091\n",
      "[000/05859] train_loss: 0.021206\n",
      "[000/05869] train_loss: 0.022037\n",
      "[000/05879] train_loss: 0.023043\n",
      "[000/05889] train_loss: 0.027656\n",
      "[000/05899] train_loss: 0.019196\n",
      "[000/05909] train_loss: 0.022760\n",
      "[000/05919] train_loss: 0.021817\n",
      "[000/05929] train_loss: 0.024364\n",
      "[000/05939] train_loss: 0.021640\n",
      "[000/05949] train_loss: 0.017358\n",
      "[000/05959] train_loss: 0.025515\n",
      "[000/05969] train_loss: 0.026174\n",
      "[000/05979] train_loss: 0.027452\n",
      "[000/05989] train_loss: 0.022270\n",
      "[000/05999] train_loss: 0.020212\n",
      "[000/05999] val_loss: 0.019525 | best_loss_val: 0.019525\n",
      "[000/06009] train_loss: 0.024472\n",
      "[000/06019] train_loss: 0.022189\n",
      "[000/06029] train_loss: 0.023763\n",
      "[000/06039] train_loss: 0.020469\n",
      "[000/06049] train_loss: 0.022236\n",
      "[000/06059] train_loss: 0.025671\n",
      "[000/06069] train_loss: 0.021463\n",
      "[000/06079] train_loss: 0.022706\n",
      "[000/06089] train_loss: 0.021034\n",
      "[000/06099] train_loss: 0.028716\n",
      "[000/06109] train_loss: 0.020759\n",
      "[000/06119] train_loss: 0.021539\n",
      "[000/06129] train_loss: 0.020075\n",
      "[000/06139] train_loss: 0.020117\n",
      "[000/06149] train_loss: 0.020222\n",
      "[000/06159] train_loss: 0.019840\n",
      "[000/06169] train_loss: 0.024991\n",
      "[000/06179] train_loss: 0.020825\n",
      "[000/06189] train_loss: 0.021755\n",
      "[000/06199] train_loss: 0.022553\n",
      "[000/06209] train_loss: 0.019110\n",
      "[000/06219] train_loss: 0.018607\n",
      "[000/06229] train_loss: 0.022641\n",
      "[000/06239] train_loss: 0.020507\n",
      "[000/06249] train_loss: 0.024154\n",
      "[000/06259] train_loss: 0.021886\n",
      "[000/06269] train_loss: 0.020256\n",
      "[000/06279] train_loss: 0.023906\n",
      "[000/06289] train_loss: 0.018911\n",
      "[000/06299] train_loss: 0.022285\n",
      "[000/06309] train_loss: 0.020182\n",
      "[000/06319] train_loss: 0.020840\n",
      "[000/06329] train_loss: 0.024622\n",
      "[000/06339] train_loss: 0.018538\n",
      "[000/06349] train_loss: 0.023072\n",
      "[000/06359] train_loss: 0.026028\n",
      "[000/06369] train_loss: 0.022492\n",
      "[000/06379] train_loss: 0.020088\n",
      "[000/06389] train_loss: 0.024539\n",
      "[000/06399] train_loss: 0.025587\n",
      "[000/06409] train_loss: 0.022009\n",
      "[000/06419] train_loss: 0.020786\n",
      "[000/06429] train_loss: 0.025068\n",
      "[000/06439] train_loss: 0.025614\n",
      "[000/06449] train_loss: 0.023520\n",
      "[000/06459] train_loss: 0.020794\n",
      "[000/06469] train_loss: 0.022777\n",
      "[000/06479] train_loss: 0.021176\n",
      "[000/06489] train_loss: 0.019531\n",
      "[000/06499] train_loss: 0.019955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0bbd1b1050>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohamed/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/mohamed/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/mohamed/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/mohamed/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n",
      "  File \"/home/mohamed/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/mohamed/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from training import vertix_train\n",
    "\n",
    "vertix_train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe04aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.inference_vertix import InferenceHandlerVertixModel\n",
    "\n",
    "# create a handler for inference using a trained checkpoint\n",
    "inferer = InferenceHandlerVertixModel('runs/vertix_training/model_best.ckpt', num_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "60263481",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = random.randint(0,len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d9be6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = train_dataset[random_sample][\"input_sdf\"]\n",
    "gt_pointcloud = train_dataset[random_sample][\"target_vertices\"]\n",
    "num_points = int(train_dataset[random_sample][\"input_mask\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c738f0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "03334c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6faa2b916d4db7b85e55bf90239128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointcloud(gt_pointcloud, point_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a0ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f2e1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pointcloud = inferer.infer_single(random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "795bd0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9ade924c8c43519b009f0920974005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointcloud(output_pointcloud, point_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651e1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
